{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04340c2b-3a8f-4a88-98b3-efcac7b8c10a",
   "metadata": {},
   "source": [
    "# 0. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "46e1b988-db8f-4ee4-8112-86df8a890119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import ee\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9f421ca0-3ff4-4bd1-91e2-89398b8a266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, losses, models, metrics, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa2ff74-d0a0-4216-aaf8-872cf0d77dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d1c1763-ce5f-4002-97be-b6efc84ff55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating add_ee_layer function\n",
    "# This allows us to visualise EE objects on a Folium map\n",
    "def add_ee_layer(self, ee_image_object, vis_params, name):\n",
    "    map_id_dict = ee_image_object.getMapId(vis_params)\n",
    "    folium.raster_layers.TileLayer(\n",
    "        tiles = map_id_dict['tile_fetcher'].url_format,\n",
    "        attr = 'Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "        name = name,\n",
    "        overlay = True,\n",
    "        control = True\n",
    "    ).add_to(self)\n",
    "\n",
    "folium.Map.add_ee_layer = add_ee_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199cfb6f-bdbb-47aa-b4ba-ca1e653c26c0",
   "metadata": {},
   "source": [
    "# 1. Uploading the data to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d036c7d-5d26-4040-a27f-e49c73544573",
   "metadata": {},
   "source": [
    "**! IMPORTANT NOTE !**\n",
    "- `THEMIS_DAYIR_TT_MergedMosaic.tif` covers all of the areas where faults are drawn, and is in EPSG 3857.\n",
    "- Tried to upload `THEMIS_DAYIR_TT_MergedMosaic.tif` directly to Earth Engine to path `projects/esg-satelite/assets/mars/features/themis_v1/pre/themis` but kept getting the following error: `Error: No data value 256.0 cannot be applied to band #0 of type Short<0, 255>. (Error code: 3)`\n",
    "- Instead uploaded `THEMIS_DAYIR_TT_MergedMosaic.tif` to GCP to path `gs://esg-satelite-data-warehouse/mars/features/themis_v1/raw/THEMIS_DayIR_TT_MergedMosaic.tif` but the image still could not be programatically moved to EE.\n",
    "- Temporarily going to use the image with path `projects/esg-satelite/assets/mars/features/themis_epsg3857_sample/pre/themis_epsg3857_sample`. This may actually be the same image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "350d5e04-7a0e-43dd-82dd-fa2e31bb752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "themis = ee.Image(\"projects/esg-satelite/assets/mars/features/themis_epsg3857_sample/pre/themis_epsg3857_sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d94b8a-092a-4394-93de-03f5e4a8c504",
   "metadata": {},
   "source": [
    "# 2. Get the data labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f98d9096-450b-442f-95c7-2bbdf3a3e501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the fault line vectors.\n",
    "faultlines = ee.FeatureCollection(\"projects/esg-satelite/assets/mars/labels/faults/pre/faults\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ab6315-b1f2-48dc-b48b-239296bb3055",
   "metadata": {},
   "source": [
    "# 3. Get train, val, and test areas for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4509871c-207a-420b-80f3-a669503055d4",
   "metadata": {},
   "source": [
    "## 3.1. Define the train, val, test areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abea7cb5-3ebb-4ed8-bc7f-6661e2bccb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the train, val, test areas of THEMIS\n",
    "PATCHES_JSON = {\n",
    "  \"type\": \"FeatureCollection\",\n",
    "  \"features\": [\n",
    "    # TRAIN\n",
    "    {\n",
    "      \"type\": \"Feature\",\n",
    "      \"properties\": {},\n",
    "      \"geometry\": {\n",
    "        \"coordinates\": [\n",
    "          [\n",
    "            [\n",
    "              -47.4,\n",
    "              20.6\n",
    "            ],\n",
    "            [\n",
    "              -38.9,\n",
    "              20.6\n",
    "            ],\n",
    "            [\n",
    "              -38.9,\n",
    "              17.4\n",
    "            ],\n",
    "            [\n",
    "              -47.4,\n",
    "              17.4,\n",
    "            ],\n",
    "            [\n",
    "              -47.4,\n",
    "              20.6\n",
    "            ]\n",
    "          ]\n",
    "        ],\n",
    "        \"type\": \"Polygon\"\n",
    "      }\n",
    "    },\n",
    "    # VAL\n",
    "    {\n",
    "      \"type\": \"Feature\",\n",
    "      \"properties\": {},\n",
    "      \"geometry\": {\n",
    "        \"coordinates\": [\n",
    "          [\n",
    "            [\n",
    "              -35.6,\n",
    "              26.4\n",
    "            ],\n",
    "            [\n",
    "              -35.6,\n",
    "              24.3\n",
    "            ],\n",
    "            [\n",
    "              -39.3,\n",
    "              24.3\n",
    "            ],\n",
    "            [\n",
    "              -39.3,\n",
    "              26.4\n",
    "            ],\n",
    "            [\n",
    "              -35.6,\n",
    "              26.4\n",
    "            ]\n",
    "          ]\n",
    "        ],\n",
    "        \"type\": \"Polygon\"\n",
    "      }\n",
    "    },\n",
    "    # TEST\n",
    "    {\n",
    "      \"type\": \"Feature\",\n",
    "      \"properties\": {},\n",
    "      \"geometry\": {\n",
    "        \"coordinates\": [\n",
    "          [\n",
    "            [\n",
    "              -42.7,\n",
    "              23.6\n",
    "            ],\n",
    "            [\n",
    "              -39.0,\n",
    "              23.6\n",
    "            ],\n",
    "            [\n",
    "              -39.0,\n",
    "              21.5\n",
    "            ],\n",
    "            [\n",
    "              -42.7,\n",
    "              21.5\n",
    "            ],\n",
    "            [\n",
    "              -42.7,\n",
    "              23.6\n",
    "            ]\n",
    "          ]\n",
    "        ],\n",
    "        \"type\": \"Polygon\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "PATCHES = ee.FeatureCollection(PATCHES_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31ed0bfd-224b-4fd8-9fcf-e554f2e04e00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_89c77d8a1376c8b4fec0f2735f02f258 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_89c77d8a1376c8b4fec0f2735f02f258&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_89c77d8a1376c8b4fec0f2735f02f258 = L.map(\n",
       "                &quot;map_89c77d8a1376c8b4fec0f2735f02f258&quot;,\n",
       "                {\n",
       "                    center: [22.7, -38.0],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 5,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_ee3851a7121c0700653c8995692c976d = L.tileLayer(\n",
       "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_89c77d8a1376c8b4fec0f2735f02f258);\n",
       "        \n",
       "    \n",
       "            var tile_layer_cc24e5a56646227f2b8816032d8854a9 = L.tileLayer(\n",
       "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/6ed3d9fdabf5d919eaffabfb1e5354f2-24546e002b23e48aa955b299fa947f37/tiles/{z}/{x}/{y}&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_89c77d8a1376c8b4fec0f2735f02f258);\n",
       "        \n",
       "    \n",
       "            var tile_layer_fc4b9b43e163ba651e1c3b8bf43e39fc = L.tileLayer(\n",
       "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/3f503dade562b6180a9e2ff398e44e6f-761de35329dbf7b7cde9f53a58740ff3/tiles/{z}/{x}/{y}&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_89c77d8a1376c8b4fec0f2735f02f258);\n",
       "        \n",
       "    \n",
       "            var tile_layer_0e88770f645f3f8fe85ef87f184a5a54 = L.tileLayer(\n",
       "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/f8a80b34195576962569ea37eebc7cb4-20c7f84abea3262b4fd5513dbf868cef/tiles/{z}/{x}/{y}&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_89c77d8a1376c8b4fec0f2735f02f258);\n",
       "        \n",
       "    \n",
       "            var layer_control_b0fff5237bc2c5ba5b89c7758b6edcac = {\n",
       "                base_layers : {\n",
       "                    &quot;openstreetmap&quot; : tile_layer_ee3851a7121c0700653c8995692c976d,\n",
       "                },\n",
       "                overlays :  {\n",
       "                    &quot;Mars THEMIS&quot; : tile_layer_cc24e5a56646227f2b8816032d8854a9,\n",
       "                    &quot;Fault Lines&quot; : tile_layer_fc4b9b43e163ba651e1c3b8bf43e39fc,\n",
       "                    &quot;Regions&quot; : tile_layer_0e88770f645f3f8fe85ef87f184a5a54,\n",
       "                },\n",
       "            };\n",
       "            L.control.layers(\n",
       "                layer_control_b0fff5237bc2c5ba5b89c7758b6edcac.base_layers,\n",
       "                layer_control_b0fff5237bc2c5ba5b89c7758b6edcac.overlays,\n",
       "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
       "            ).addTo(map_89c77d8a1376c8b4fec0f2735f02f258);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f9fcb5f62d0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the train, val, and test areas on a map\n",
    "Map = folium.Map(location = [22.7, -38], zoom_start = 5)\n",
    "\n",
    "Map.add_ee_layer(\n",
    "    themis,\n",
    "    {},\n",
    "    \"Mars THEMIS\"\n",
    ")\n",
    "\n",
    "Map.add_ee_layer(\n",
    "    faultlines,\n",
    "    {\"min\": 0, \"max\": 1, \"color\": \"red\"},\n",
    "    \"Fault Lines\"\n",
    ")\n",
    "\n",
    "Map.add_ee_layer(\n",
    "    PATCHES,\n",
    "    {},\n",
    "    \"Regions\"\n",
    ")\n",
    "\n",
    "_ = folium.LayerControl().add_to(Map)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c4762c-4d94-4930-8fd5-c39f61682b5d",
   "metadata": {},
   "source": [
    "- Bottom: Train\n",
    "    - x width = 8.5 deg\n",
    "    - y height = 3.2 deg\n",
    "- Top: Val\n",
    "    - x width = 3.7 deg\n",
    "    - y height = 2.1 deg\n",
    "- Middle: Test\n",
    "    - x width = 3.7 deg\n",
    "    - y height = 2.1 deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbebadf-0a4c-49fe-990b-849c38e300d6",
   "metadata": {},
   "source": [
    "**! IMPORTANT NOTE !**\n",
    "- Attempts have been made to separate the train, val, and test areas such that sample images taken won't overlap.\n",
    "- However, this may not be guaranteed, and needs checking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdd81ea-d10b-4b8c-8d74-f12cb54efb5e",
   "metadata": {},
   "source": [
    "## 3.2. Generate data samples from these areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91758dc2-9533-428b-b188-950880b679df",
   "metadata": {},
   "source": [
    "### 3.2.1 Create faultline raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3307a18f-f5c1-4775-b794-a85012ced7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a columns of ones \n",
    "# This assigns each geometry (each fault/vector) to the value 1\n",
    "# and assigns every other space to nothing (which we will fix later)\n",
    "def add_column(feature):\n",
    "    return feature.set({\"Value\": 1})\n",
    "\n",
    "faultline_vectors_with_ones = faultlines.map(add_column)\n",
    "\n",
    "faultlines_raster = (\n",
    "    # Convert to image\n",
    "    faultline_vectors_with_ones.reduceToImage(\n",
    "        properties=[\"Value\"],\n",
    "        reducer=ee.Reducer.first()\n",
    "    )\n",
    "    # Change band name \"first\"  to \"FAULTLINE\" \n",
    "    .select([\"first\"], [\"FAULTLINE\"])\n",
    "    # Unmask, which changes all non-fault pixels to have value 0\n",
    "    .unmask(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd41d01-e5aa-4525-a848-2be64973a068",
   "metadata": {},
   "source": [
    "### 3.2.2. Stack the features and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7703ff1e-1490-4d71-9c3a-6976f7034b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stack\n",
    "image_stack = ee.Image.cat(\n",
    "    [\n",
    "        faultlines_raster,\n",
    "        themis\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3eee4fc7-5fd3-4fa5-b181-5d33b7f61313",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stack = image_stack.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a002a1-b1e7-4466-aed4-6b260a8d89f8",
   "metadata": {},
   "source": [
    "### 3.3.3. Sample the stack in the areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b92b1486-d743-4136-9aa7-e3fffc2b1c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f125b95-4824-44b1-8498-50a51648631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a 64x64 tensor of 1s\n",
    "# This is because we want, for each pixel, to take every 64x64 pixel around that one\n",
    "# The 1s just mean we aren't applying any kind of transformation\n",
    "ee_list = ee.List.repeat(1,KERNEL_SIZE)\n",
    "ee_lists = ee.List.repeat(ee_list,KERNEL_SIZE)\n",
    "kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, ee_lists)\n",
    "\n",
    "image_stack_neighbours = image_stack.neighborhoodToArray(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3538fbc-4732-4c02-aecf-ec75d6c44949",
   "metadata": {},
   "source": [
    "- We generate..\n",
    "    - 4000 sample images for the train set\n",
    "    - 1000 for the validation set\n",
    "    - 1000 for the test set\n",
    "    - all of size 128x128\n",
    "    - all of scale 500\n",
    "- The validation (and test) set is 28% the size of the train set; this is where the 1000 vs 4000 came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c2e4624-b9c8-45df-a24a-ca6c307efac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_list = PATCHES.toList(PATCHES.size())\n",
    "\n",
    "task_list = []\n",
    "names = [\"train\", \"val\", \"test\"]\n",
    "number_of_shards = [400, 100, 100]\n",
    "sample_size = [4000, 1000, 1000]\n",
    "\n",
    "# Extracts feature from the feature collection, and gets the geom property\n",
    "for geometry_index in range(PATCHES.size().getInfo()):\n",
    "    \n",
    "    image_stack_sample = ee.FeatureCollection([])\n",
    "    for i in range(number_of_shards[geometry_index]):\n",
    "        \n",
    "        sample = image_stack_neighbours.sample(\n",
    "            region=ee.Feature(patch_list.get(geometry_index)).geometry(),\n",
    "            scale=500,\n",
    "            numPixels=(sample_size[geometry_index])/(number_of_shards[geometry_index]),\n",
    "            seed=i\n",
    "        )\n",
    "        image_stack_sample = image_stack_sample.merge(sample)\n",
    "        \n",
    "    desc = f\"Features and Labels for region: {names[geometry_index]}\"\n",
    "    task = ee.batch.Export.table.toCloudStorage(\n",
    "        collection=image_stack_sample,\n",
    "        description=desc,\n",
    "        bucket=\"esg-satelite-data-warehouse\",\n",
    "        fileNamePrefix=f\"mars/modelling/themis_v1/data_{names[geometry_index]}\",\n",
    "        fileFormat = \"TFRecord\"\n",
    "    )\n",
    "    task_list.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f6255fa-c273-4224-9a4a-90f9f6861290",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in task_list:\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d330889d-9bed-4d94-9696-c271cb55ba49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'RUNNING',\n",
       " 'description': 'Features and Labels for region: train',\n",
       " 'creation_timestamp_ms': 1697662221256,\n",
       " 'update_timestamp_ms': 1697662341174,\n",
       " 'start_timestamp_ms': 1697662243611,\n",
       " 'task_type': 'EXPORT_FEATURES',\n",
       " 'attempt': 1,\n",
       " 'id': 'BS55TCITDQWCD4XYOZ5ZNDPQ',\n",
       " 'name': 'projects/earthengine-legacy/operations/BS55TCITDQWCD4XYOZ5ZNDPQ'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_list[0].status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d47a91b-b084-4da6-9503-542a0025cee3",
   "metadata": {},
   "source": [
    "# 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e6673781-2246-4077-a4e2-2cf29b3b87d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS = [\"b1\"]\n",
    "RESPONSE = \"FAULTLINE\"\n",
    "FEATURES = BANDS + [RESPONSE]\n",
    "\n",
    "COLUMNS = [\n",
    "    tf.io.FixedLenFeature(shape=[KERNEL_SIZE, KERNEL_SIZE], dtype=tf.float32) for _ in FEATURES\n",
    "]\n",
    "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3962ad13-2dc8-4144-9076-31ed402c3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(example_proto):\n",
    "    \"\"\"The parsing function.\n",
    "    Read a serialized example into the structure defined by FEATURES_DICT.\n",
    "    Args:\n",
    "    example_proto: a serialized Example.\n",
    "    Returns:\n",
    "    A dictionary of tensors, keyed by feature name.\n",
    "    \"\"\"\n",
    "    return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
    "\n",
    "\n",
    "def to_tuple(inputs):\n",
    "    \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
    "    Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
    "    Args:\n",
    "    inputs: A dictionary of tensors, keyed by feature name.\n",
    "    Returns:\n",
    "    A tuple of (inputs, outputs).\n",
    "    \"\"\"\n",
    "    inputsList = [inputs.get(key) for key in FEATURES]\n",
    "    stacked = tf.stack(inputsList, axis=0)\n",
    "    # Convert from CHW to HWC\n",
    "    stacked = tf.transpose(stacked, [1, 2, 0])\n",
    "    return stacked[:,:,:len(BANDS)], tf.squeeze(tf.cast(stacked[:,:,len(BANDS):], tf.int32))\n",
    "\n",
    "\n",
    "def get_dataset(pattern):\n",
    "    \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
    "    Get all the files matching the pattern, parse and convert to tuple.\n",
    "    Args:\n",
    "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
    "    Returns:\n",
    "    A tf.data.Dataset\n",
    "    \"\"\"\n",
    "    glob = tf.io.gfile.glob(pattern)\n",
    "    dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
    "    dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
    "    dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b367c715-d414-4865-96d3-6d204eba404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7232cd0-f3ef-4275-97e2-f761901c5c84",
   "metadata": {},
   "source": [
    "## 4.1. Get the TensorFlow records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3eb88c86-07c3-472d-a520-5a246fc019f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 20:56:57.330866: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-18 20:56:57.341926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-18 20:56:57.343487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-18 20:56:57.369913: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-18 20:56:57.371684: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-18 20:56:57.373276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-18 20:56:57.374774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-18 20:56:59.151027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-18 20:56:59.153769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-18 20:56:59.155318: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-18 20:56:59.157661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13582 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 2000\n",
    "\n",
    "base_path = \"gs://esg-satelite-data-warehouse/mars/modelling/themis_v1\"\n",
    "\n",
    "\n",
    "train_data_path = f\"{base_path}/data_train.tfrecord.gz\"\n",
    "test_data_path = f\"{base_path}/data_test.tfrecord.gz\"\n",
    "val_data_path = f\"{base_path}/data_val.tfrecord.gz\"\n",
    "\n",
    "train_data_raw = get_dataset(train_data_path)\n",
    "test_data_raw = get_dataset(test_data_path)\n",
    "val_data_raw = get_dataset(val_data_path)\n",
    "\n",
    "\n",
    "training_data = train_data_raw.shuffle(BUFFER_SIZE, reshuffle_each_iteration = False).batch(BATCH_SIZE)\n",
    "test_data = test_data_raw.shuffle(BUFFER_SIZE, reshuffle_each_iteration = False).batch(BATCH_SIZE)\n",
    "val_data = val_data_raw.shuffle(BUFFER_SIZE, reshuffle_each_iteration = False).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045d9200-da68-43f0-9e66-8375186ef688",
   "metadata": {},
   "source": [
    "## 4.2. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "502e7662-7321-4c19-8775-4da6b29d1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters):\n",
    "    encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
    "    encoder = layers.BatchNormalization()(encoder)\n",
    "    encoder = layers.Activation('relu')(encoder)\n",
    "    encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
    "    encoder = layers.BatchNormalization()(encoder)\n",
    "    encoder = layers.Activation('relu')(encoder)\n",
    "    return encoder\n",
    "\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "    encoder = conv_block(input_tensor, num_filters)\n",
    "    encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
    "    return encoder_pool, encoder\n",
    "\n",
    "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
    "    decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
    "    decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    return decoder\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    normalisation_layer = layers.Normalization()\n",
    "    normalisation_layer.adapt(training_data.map(lambda x, _: x))\n",
    "\n",
    "    inputs = layers.Input(shape=[None, None, len(BANDS)]) # 256\n",
    "    normalised_inputs = normalisation_layer(inputs)\n",
    "    encoder0_pool, encoder0 = encoder_block(normalised_inputs, 32) # 128\n",
    "    encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64) # 64\n",
    "    encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128) # 32\n",
    "    encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
    "    encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
    "    center = conv_block(encoder4_pool, 1024) # center\n",
    "    decoder4 = decoder_block(center, encoder4, 512) # 16\n",
    "    decoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
    "    decoder2 = decoder_block(decoder3, encoder2, 128) # 64\n",
    "    decoder1 = decoder_block(decoder2, encoder1, 64) # 128\n",
    "    decoder0 = decoder_block(decoder1, encoder0, 32) # 256\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation=\"sigmoid\")(decoder0)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.SGD(learning_rate=0.1), \n",
    "        #loss=losses.BinaryCrossentropy(),\n",
    "        loss = weightedLoss(keras.losses.categorical_crossentropy, [0.1,0.9]),\n",
    "        metrics=[\n",
    "            metrics.BinaryIoU(target_class_ids=[1], name = \"iou\")\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1a86d34b-02eb-4795-a96a-2b596b9e3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedLoss(originalLossFunc, weightsList):\n",
    "\n",
    "    def lossFunc(true, pred):\n",
    "\n",
    "        axis = -1 #if channels last \n",
    "        #axis=  1 #if channels first\n",
    "\n",
    "\n",
    "        #argmax returns the index of the element with the greatest value\n",
    "        #done in the class axis, it returns the class index    \n",
    "        classSelectors = K.argmax(true, axis=axis) \n",
    "            #if your loss is sparse, use only true as classSelectors\n",
    "\n",
    "        #considering weights are ordered by class, for each class\n",
    "        #true(1) if the class index is equal to the weight index   \n",
    "        classSelectors = [K.equal(int(i), int(classSelectors)) for i in range(len(weightsList))]\n",
    "\n",
    "        #casting boolean to float for calculations  \n",
    "        #each tensor in the list contains 1 where ground true class is equal to its index \n",
    "        #if you sum all these, you will get a tensor full of ones. \n",
    "        classSelectors = [K.cast(x, K.floatx()) for x in classSelectors]\n",
    "\n",
    "        #for each of the selections above, multiply their respective weight\n",
    "        weights = [sel * w for sel,w in zip(classSelectors, weightsList)] \n",
    "\n",
    "        #sums all the selections\n",
    "        #result is a tensor with the respective weight for each element in predictions\n",
    "        weightMultiplier = weights[0]\n",
    "        for i in range(1, len(weights)):\n",
    "            weightMultiplier = weightMultiplier + weights[i]\n",
    "\n",
    "\n",
    "        #make sure your originalLossFunc only collapses the class axis\n",
    "        #you need the other axes intact to multiply the weights tensor\n",
    "        loss = originalLossFunc(true,pred) \n",
    "        loss = loss * weightMultiplier\n",
    "\n",
    "        return loss\n",
    "    return lossFunc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dac305-b421-4a61-804c-32b3dcd341b8",
   "metadata": {},
   "source": [
    "## 4.3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "721f7a96-04d0-43d9-a76f-cf92c3d170c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "es = EarlyStopping(\n",
    "    monitor= \"val_iou\",\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode=\"max\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "callbacks.append(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c784f976-3675-47b1-892f-c3accfd1fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2459163b-52ae-4dcf-83bf-2babbd43da6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 42s 140ms/step - loss: 13.3551 - iou: 0.4228 - val_loss: 10.0002 - val_iou: 0.3155\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 37s 140ms/step - loss: 13.0440 - iou: 0.4791 - val_loss: 9.9641 - val_iou: 0.3342\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 37s 144ms/step - loss: 12.8827 - iou: 0.4981 - val_loss: 10.0835 - val_iou: 0.3420\n",
      "Epoch 4/10\n",
      "134/250 [===============>..............] - ETA: 14s - loss: 12.6219 - iou: 0.5098"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(\n",
    "    x=training_data,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_data,\n",
    "    callbacks = callbacks,\n",
    "    #class_weight= {0: 0.10, 1: 0.90}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8acd905-86aa-487c-ae74-fb4bfa30e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to change categorical_crossentropy to binary cross entropy "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m107"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
